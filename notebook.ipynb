{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ukrainian telegram messages research\n",
    "#### Vynokury\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "This notebook requires theese modules to be installed:\n",
    "- pandas\n",
    "- matplotlb\n",
    "- geopandas\n",
    "- nltk\n",
    "- pymorphy3\n",
    "- pymorphy3-dicts-uk\n",
    "- wordcloud\n",
    "\n",
    "Project executors:\n",
    "- Andrii Kryvyi\n",
    "- Nikita Lenyk\n",
    "- Ostap Kostiuk\n",
    "- Luka Konovalov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.12/site-packages (3.9.3)\n",
      "Requirement already satisfied: geopandas in ./venv/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: pymorphy3 in ./venv/lib/python3.12/site-packages (2.0.2)\n",
      "Requirement already satisfied: pymorphy3-dicts-uk in ./venv/lib/python3.12/site-packages (2.4.1.1.1663094765)\n",
      "Requirement already satisfied: nltk in ./venv/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: wordcloud in ./venv/lib/python3.12/site-packages (1.9.4)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./venv/lib/python3.12/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.12/site-packages (from matplotlib) (4.55.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.12/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.12/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in ./venv/lib/python3.12/site-packages (from geopandas) (0.10.0)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in ./venv/lib/python3.12/site-packages (from geopandas) (3.7.0)\n",
      "Requirement already satisfied: shapely>=2.0.0 in ./venv/lib/python3.12/site-packages (from geopandas) (2.0.6)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in ./venv/lib/python3.12/site-packages (from pymorphy3) (0.7.2)\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in ./venv/lib/python3.12/site-packages (from pymorphy3) (2.4.417150.4580142)\n",
      "Requirement already satisfied: setuptools>=68.2.2 in ./venv/lib/python3.12/site-packages (from pymorphy3) (75.6.0)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from pyogrio>=0.7.2->geopandas) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas matplotlib geopandas pymorphy3 pymorphy3-dicts-uk nltk wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing\n",
    "\n",
    "In this part we initialize required modules, read dataset and clean it (analyzing it dirtiness)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setuping Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import nltk\n",
    "import re\n",
    "import pymorphy3\n",
    "import wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize NLP modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /var/home/andriy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "\n",
    "morph = pymorphy3.MorphAnalyzer(lang=\"uk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read map of Ukraine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((35.23342 45.79173, 35.22632 45.81739...</td>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((25.11276 50.28727, 25.11147 50.29428...</td>\n",
       "      <td>–í–æ–ª–∏–Ω—Å—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((25.11276 50.28727, 25.11291 50.28489...</td>\n",
       "      <td>–†—ñ–≤–Ω–µ–Ω—Å—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((27.19595 50.56224, 27.19661 50.55239...</td>\n",
       "      <td>–ñ–∏—Ç–æ–º–∏—Ä—Å—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MULTIPOLYGON (((30.34907 50.48887, 30.34605 50...</td>\n",
       "      <td>–ö–∏—ó–≤—Å—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>POLYGON ((32.14266 50.34881, 32.2184 50.35759,...</td>\n",
       "      <td>–ß–µ—Ä–Ω—ñ–≥—ñ–≤—Å—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>POLYGON ((33.06618 50.51985, 33.06913 50.51844...</td>\n",
       "      <td>–°—É–º—Å—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>POLYGON ((34.94082 50.15259, 34.93279 50.13471...</td>\n",
       "      <td>–•–∞—Ä–∫—ñ–≤—Å—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>POLYGON ((37.87444 49.23388, 37.87342 49.22317...</td>\n",
       "      <td>–õ—É–≥–∞–Ω—Å—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>POLYGON ((36.73891 48.62595, 36.74531 48.59654...</td>\n",
       "      <td>–î–æ–Ω–µ—Ü—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>POLYGON ((35.46804 46.14649, 35.48195 46.15662...</td>\n",
       "      <td>–ó–∞–ø–æ—Ä—ñ–∑—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>POLYGON ((24.09819 50.63744, 24.09123 50.61912...</td>\n",
       "      <td>–õ—å–≤—ñ–≤—Å—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>POLYGON ((23.54761 48.7258, 23.5541 48.72448, ...</td>\n",
       "      <td>–Ü–≤–∞–Ω–æ-–§—Ä–∞–Ω–∫—ñ–≤—Å—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>POLYGON ((22.88901 49.00685, 22.88264 49.00687...</td>\n",
       "      <td>–ó–∞–∫–∞—Ä–ø–∞—Ç—Å—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>POLYGON ((25.34674 50.00405, 25.36113 49.99602...</td>\n",
       "      <td>–¢–µ—Ä–Ω–æ–ø—ñ–ª—å—Å—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>POLYGON ((24.92248 47.72629, 24.9471 47.72922,...</td>\n",
       "      <td>–ß–µ—Ä–Ω—ñ–≤–µ—Ü—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>POLYGON ((31.1591 46.40968, 31.17698 46.62864,...</td>\n",
       "      <td>–û–¥–µ—Å—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>POLYGON ((33.09268 47.57883, 33.09501 47.59711...</td>\n",
       "      <td>–ú–∏–∫–æ–ª–∞—ó–≤—Å—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>POLYGON ((32.7727 45.82664, 32.73967 45.80732,...</td>\n",
       "      <td>–ê–≤—Ç–æ–Ω–æ–º–Ω–∞ –†–µ—Å–ø—É–±–ª—ñ–∫–∞ –ö—Ä–∏–º</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>POLYGON ((27.81701 49.73467, 27.8367 49.72984,...</td>\n",
       "      <td>–í—ñ–Ω–Ω–∏—Ü—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>POLYGON ((26.22048 50.1797, 26.21117 50.17482,...</td>\n",
       "      <td>–•–º–µ–ª—å–Ω–∏—Ü—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>POLYGON ((29.73607 49.22898, 29.73506 49.2265,...</td>\n",
       "      <td>–ß–µ—Ä–∫–∞—Å—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>POLYGON ((32.11624 50.22858, 32.12553 50.22466...</td>\n",
       "      <td>–ü–æ–ª—Ç–∞–≤—Å—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>POLYGON ((34.13946 47.47725, 34.20739 47.48826...</td>\n",
       "      <td>–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>POLYGON ((30.30699 48.14198, 30.31647 48.14128...</td>\n",
       "      <td>–ö—ñ—Ä–æ–≤–æ–≥—Ä–∞–¥—Å—å–∫–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>POLYGON ((30.82758 50.4054, 30.82614 50.40457,...</td>\n",
       "      <td>–ö–∏—ó–≤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>POLYGON ((33.29519 44.94052, 33.28537 44.92755...</td>\n",
       "      <td>–°–µ–≤–∞—Å—Ç–æ–ø–æ–ª—å</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             geometry  \\\n",
       "0   POLYGON ((35.23342 45.79173, 35.22632 45.81739...   \n",
       "1   POLYGON ((25.11276 50.28727, 25.11147 50.29428...   \n",
       "2   POLYGON ((25.11276 50.28727, 25.11291 50.28489...   \n",
       "3   POLYGON ((27.19595 50.56224, 27.19661 50.55239...   \n",
       "4   MULTIPOLYGON (((30.34907 50.48887, 30.34605 50...   \n",
       "5   POLYGON ((32.14266 50.34881, 32.2184 50.35759,...   \n",
       "6   POLYGON ((33.06618 50.51985, 33.06913 50.51844...   \n",
       "7   POLYGON ((34.94082 50.15259, 34.93279 50.13471...   \n",
       "8   POLYGON ((37.87444 49.23388, 37.87342 49.22317...   \n",
       "9   POLYGON ((36.73891 48.62595, 36.74531 48.59654...   \n",
       "10  POLYGON ((35.46804 46.14649, 35.48195 46.15662...   \n",
       "11  POLYGON ((24.09819 50.63744, 24.09123 50.61912...   \n",
       "12  POLYGON ((23.54761 48.7258, 23.5541 48.72448, ...   \n",
       "13  POLYGON ((22.88901 49.00685, 22.88264 49.00687...   \n",
       "14  POLYGON ((25.34674 50.00405, 25.36113 49.99602...   \n",
       "15  POLYGON ((24.92248 47.72629, 24.9471 47.72922,...   \n",
       "16  POLYGON ((31.1591 46.40968, 31.17698 46.62864,...   \n",
       "17  POLYGON ((33.09268 47.57883, 33.09501 47.59711...   \n",
       "18  POLYGON ((32.7727 45.82664, 32.73967 45.80732,...   \n",
       "19  POLYGON ((27.81701 49.73467, 27.8367 49.72984,...   \n",
       "20  POLYGON ((26.22048 50.1797, 26.21117 50.17482,...   \n",
       "21  POLYGON ((29.73607 49.22898, 29.73506 49.2265,...   \n",
       "22  POLYGON ((32.11624 50.22858, 32.12553 50.22466...   \n",
       "23  POLYGON ((34.13946 47.47725, 34.20739 47.48826...   \n",
       "24  POLYGON ((30.30699 48.14198, 30.31647 48.14128...   \n",
       "25  POLYGON ((30.82758 50.4054, 30.82614 50.40457,...   \n",
       "26  POLYGON ((33.29519 44.94052, 33.28537 44.92755...   \n",
       "\n",
       "                       region  \n",
       "0                  –•–µ—Ä—Å–æ–Ω—Å—å–∫–∞  \n",
       "1                   –í–æ–ª–∏–Ω—Å—å–∫–∞  \n",
       "2                  –†—ñ–≤–Ω–µ–Ω—Å—å–∫–∞  \n",
       "3                 –ñ–∏—Ç–æ–º–∏—Ä—Å—å–∫–∞  \n",
       "4                    –ö–∏—ó–≤—Å—å–∫–∞  \n",
       "5                –ß–µ—Ä–Ω—ñ–≥—ñ–≤—Å—å–∫–∞  \n",
       "6                     –°—É–º—Å—å–∫–∞  \n",
       "7                  –•–∞—Ä–∫—ñ–≤—Å—å–∫–∞  \n",
       "8                   –õ—É–≥–∞–Ω—Å—å–∫–∞  \n",
       "9                    –î–æ–Ω–µ—Ü—å–∫–∞  \n",
       "10                 –ó–∞–ø–æ—Ä—ñ–∑—å–∫–∞  \n",
       "11                  –õ—å–≤—ñ–≤—Å—å–∫–∞  \n",
       "12          –Ü–≤–∞–Ω–æ-–§—Ä–∞–Ω–∫—ñ–≤—Å—å–∫–∞  \n",
       "13               –ó–∞–∫–∞—Ä–ø–∞—Ç—Å—å–∫–∞  \n",
       "14              –¢–µ—Ä–Ω–æ–ø—ñ–ª—å—Å—å–∫–∞  \n",
       "15                –ß–µ—Ä–Ω—ñ–≤–µ—Ü—å–∫–∞  \n",
       "16                    –û–¥–µ—Å—å–∫–∞  \n",
       "17               –ú–∏–∫–æ–ª–∞—ó–≤—Å—å–∫–∞  \n",
       "18  –ê–≤—Ç–æ–Ω–æ–º–Ω–∞ –†–µ—Å–ø—É–±–ª—ñ–∫–∞ –ö—Ä–∏–º  \n",
       "19                  –í—ñ–Ω–Ω–∏—Ü—å–∫–∞  \n",
       "20                –•–º–µ–ª—å–Ω–∏—Ü—å–∫–∞  \n",
       "21                  –ß–µ—Ä–∫–∞—Å—å–∫–∞  \n",
       "22                 –ü–æ–ª—Ç–∞–≤—Å—å–∫–∞  \n",
       "23           –î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞  \n",
       "24             –ö—ñ—Ä–æ–≤–æ–≥—Ä–∞–¥—Å—å–∫–∞  \n",
       "25                       –ö–∏—ó–≤  \n",
       "26                –°–µ–≤–∞—Å—Ç–æ–ø–æ–ª—å  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iso_regions = {\n",
    "    \"UA-65\": \"–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞\",\n",
    "    \"UA-07\": \"–í–æ–ª–∏–Ω—Å—å–∫–∞\",\n",
    "    \"UA-56\": \"–†—ñ–≤–Ω–µ–Ω—Å—å–∫–∞\",\n",
    "    \"UA-18\": \"–ñ–∏—Ç–æ–º–∏—Ä—Å—å–∫–∞\",\n",
    "    \"UA-32\": \"–ö–∏—ó–≤—Å—å–∫–∞\",\n",
    "    \"UA-74\": \"–ß–µ—Ä–Ω—ñ–≥—ñ–≤—Å—å–∫–∞\",\n",
    "    \"UA-59\": \"–°—É–º—Å—å–∫–∞\",\n",
    "    \"UA-63\": \"–•–∞—Ä–∫—ñ–≤—Å—å–∫–∞\",\n",
    "    \"UA-09\": \"–õ—É–≥–∞–Ω—Å—å–∫–∞\",\n",
    "    \"UA-14\": \"–î–æ–Ω–µ—Ü—å–∫–∞\",\n",
    "    \"UA-23\": \"–ó–∞–ø–æ—Ä—ñ–∑—å–∫–∞\",\n",
    "    \"UA-46\": \"–õ—å–≤—ñ–≤—Å—å–∫–∞\",\n",
    "    \"UA-26\": \"–Ü–≤–∞–Ω–æ-–§—Ä–∞–Ω–∫—ñ–≤—Å—å–∫–∞\",\n",
    "    \"UA-21\": \"–ó–∞–∫–∞—Ä–ø–∞—Ç—Å—å–∫–∞\",\n",
    "    \"UA-61\": \"–¢–µ—Ä–Ω–æ–ø—ñ–ª—å—Å—å–∫–∞\",\n",
    "    \"UA-77\": \"–ß–µ—Ä–Ω—ñ–≤–µ—Ü—å–∫–∞\",\n",
    "    \"UA-51\": \"–û–¥–µ—Å—å–∫–∞\",\n",
    "    \"UA-48\": \"–ú–∏–∫–æ–ª–∞—ó–≤—Å—å–∫–∞\",\n",
    "    \"UA-43\": \"–ê–≤—Ç–æ–Ω–æ–º–Ω–∞ –†–µ—Å–ø—É–±–ª—ñ–∫–∞ –ö—Ä–∏–º\",\n",
    "    \"UA-05\": \"–í—ñ–Ω–Ω–∏—Ü—å–∫–∞\",\n",
    "    \"UA-68\": \"–•–º–µ–ª—å–Ω–∏—Ü—å–∫–∞\",\n",
    "    \"UA-71\": \"–ß–µ—Ä–∫–∞—Å—å–∫–∞\",\n",
    "    \"UA-53\": \"–ü–æ–ª—Ç–∞–≤—Å—å–∫–∞\",\n",
    "    \"UA-12\": \"–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞\",\n",
    "    \"UA-35\": \"–ö—ñ—Ä–æ–≤–æ–≥—Ä–∞–¥—Å—å–∫–∞\",\n",
    "    \"UA-30\": \"–ö–∏—ó–≤\",\n",
    "    \"UA-40\": \"–°–µ–≤–∞—Å—Ç–æ–ø–æ–ª—å\",\n",
    "}\n",
    "\n",
    "map_ = gpd.read_file(\"ukrainian_map.geojson\")\n",
    "map_[\"region\"] = map_.shapeISO.map(iso_regions)\n",
    "map_ = map_.drop(\n",
    "    columns=[\"shapeName\", \"shapeISO\", \"shapeID\", \"shapeGroup\", \"shapeType\"]\n",
    ")\n",
    "map_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset\n",
    "\n",
    "Dataset is placed in the `message-weather.csv` file in a csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>date_weather</th>\n",
       "      <th>latitude_decimal</th>\n",
       "      <th>longitude_decimal</th>\n",
       "      <th>max_temperature</th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>region_x</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>date_hour_x</th>\n",
       "      <th>tg_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–°—É–º–∏</td>\n",
       "      <td>2022-12-02 12:32</td>\n",
       "      <td>50.911944</td>\n",
       "      <td>34.803333</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>–°—É–º—Å—å–∫–∞</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>343</td>\n",
       "      <td>31.2</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>2022-12-02 12:00:00</td>\n",
       "      <td>üí• –•–æ—Ç—ñ–Ω—å (–°—É–º—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞—Ä—Ç–∏–ª–µ—Ä—ñ–π—Å—å–∫–æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–ú–∞—Ä–≥–∞–Ω–µ—Ü—å</td>\n",
       "      <td>2022-12-02 11:33</td>\n",
       "      <td>47.644722</td>\n",
       "      <td>34.604167</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3</td>\n",
       "      <td>28.5</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>2022-12-02 11:00:00</td>\n",
       "      <td>üí• –ú–∞—Ä–≥–∞–Ω–µ—Ü—å (–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–î–Ω—ñ–ø—Ä–æ</td>\n",
       "      <td>2022-12-02 11:33</td>\n",
       "      <td>48.466111</td>\n",
       "      <td>35.025278</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞</td>\n",
       "      <td>1.7</td>\n",
       "      <td>357</td>\n",
       "      <td>29.9</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>2022-12-02 11:00:00</td>\n",
       "      <td>üí• –ú–∞—Ä–≥–∞–Ω–µ—Ü—å (–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–ù—ñ–∫–æ–ø–æ–ª—å</td>\n",
       "      <td>2022-12-02 11:33</td>\n",
       "      <td>47.577222</td>\n",
       "      <td>34.357500</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7</td>\n",
       "      <td>25.4</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>2022-12-02 11:00:00</td>\n",
       "      <td>üí• –ú–∞—Ä–≥–∞–Ω–µ—Ü—å (–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–î–Ω—ñ–ø—Ä–æ</td>\n",
       "      <td>2022-12-02 11:33</td>\n",
       "      <td>48.466111</td>\n",
       "      <td>35.025278</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞</td>\n",
       "      <td>1.7</td>\n",
       "      <td>357</td>\n",
       "      <td>29.9</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>2022-12-02 11:00:00</td>\n",
       "      <td>üí• –ú–∞—Ä–≥–∞–Ω–µ—Ü—å (–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8798</th>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω</td>\n",
       "      <td>2023-04-01 09:06</td>\n",
       "      <td>46.640000</td>\n",
       "      <td>32.614444</td>\n",
       "      <td>18.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞</td>\n",
       "      <td>16.9</td>\n",
       "      <td>248</td>\n",
       "      <td>45.4</td>\n",
       "      <td>Mainly clear</td>\n",
       "      <td>2023-04-01 09:00:00</td>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å. –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è —â–æ–¥–æ –≤–æ—Ä–æ–∂–∏—Ö –æ–±...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8799</th>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω</td>\n",
       "      <td>2023-03-30 16:20</td>\n",
       "      <td>46.640000</td>\n",
       "      <td>32.614444</td>\n",
       "      <td>16.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞</td>\n",
       "      <td>10.7</td>\n",
       "      <td>245</td>\n",
       "      <td>27.7</td>\n",
       "      <td>Mainly clear</td>\n",
       "      <td>2023-03-30 16:00:00</td>\n",
       "      <td>‚Äã‚Äã‚ö°Ô∏è–û—Ç—Ä–∏–º–∞–≤ –æ—Å–∫–æ–ª–∫–æ–≤–µ –ø–æ—Ä–∞–Ω–µ–Ω–Ω—è –ø—ñ–¥ —á–∞—Å –±–æ–º–±–∞—Ä...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8800</th>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω</td>\n",
       "      <td>2023-03-10 08:43</td>\n",
       "      <td>46.640000</td>\n",
       "      <td>32.614444</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>65</td>\n",
       "      <td>36.1</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>2023-03-10 08:00:00</td>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å. –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è —â–æ–¥–æ –≤–æ—Ä–æ–∂–∏—Ö –æ–±...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8801</th>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω</td>\n",
       "      <td>2023-03-10 08:43</td>\n",
       "      <td>46.640000</td>\n",
       "      <td>32.614444</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>65</td>\n",
       "      <td>36.1</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>2023-03-10 08:00:00</td>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å. –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è —â–æ–¥–æ –≤–æ—Ä–æ–∂–∏—Ö –æ–±...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8802</th>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω</td>\n",
       "      <td>2023-03-09 11:25</td>\n",
       "      <td>46.640000</td>\n",
       "      <td>32.614444</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞</td>\n",
       "      <td>2.6</td>\n",
       "      <td>83</td>\n",
       "      <td>22.1</td>\n",
       "      <td>Drizzle: Light</td>\n",
       "      <td>2023-03-09 11:00:00</td>\n",
       "      <td>–ù–∞ –≤—ñ–¥–µ–æ - –ø–ª–æ—â–∞ –ö–æ—Ä–∞–±–µ–ª—å–Ω–∞ —É –•–µ—Ä—Å–æ–Ω—ñ. \\n\\n–ù–∞ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8803 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           city      date_weather  latitude_decimal  longitude_decimal  \\\n",
       "0          –°—É–º–∏  2022-12-02 12:32         50.911944          34.803333   \n",
       "1     –ú–∞—Ä–≥–∞–Ω–µ—Ü—å  2022-12-02 11:33         47.644722          34.604167   \n",
       "2        –î–Ω—ñ–ø—Ä–æ  2022-12-02 11:33         48.466111          35.025278   \n",
       "3      –ù—ñ–∫–æ–ø–æ–ª—å  2022-12-02 11:33         47.577222          34.357500   \n",
       "4        –î–Ω—ñ–ø—Ä–æ  2022-12-02 11:33         48.466111          35.025278   \n",
       "...         ...               ...               ...                ...   \n",
       "8798     –•–µ—Ä—Å–æ–Ω  2023-04-01 09:06         46.640000          32.614444   \n",
       "8799     –•–µ—Ä—Å–æ–Ω  2023-03-30 16:20         46.640000          32.614444   \n",
       "8800     –•–µ—Ä—Å–æ–Ω  2023-03-10 08:43         46.640000          32.614444   \n",
       "8801     –•–µ—Ä—Å–æ–Ω  2023-03-10 08:43         46.640000          32.614444   \n",
       "8802     –•–µ—Ä—Å–æ–Ω  2023-03-09 11:25         46.640000          32.614444   \n",
       "\n",
       "      max_temperature  min_temperature          region_x  temperature  \\\n",
       "0                -0.2             -3.3           –°—É–º—Å—å–∫–∞         -0.2   \n",
       "1                 2.7             -0.1  –î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞          2.7   \n",
       "2                 1.7             -1.6  –î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞          1.7   \n",
       "3                 2.4              0.1  –î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞          2.4   \n",
       "4                 1.7             -1.6  –î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞          1.7   \n",
       "...               ...              ...               ...          ...   \n",
       "8798             18.1             10.2        –•–µ—Ä—Å–æ–Ω—Å—å–∫–∞         16.9   \n",
       "8799             16.2              3.1        –•–µ—Ä—Å–æ–Ω—Å—å–∫–∞         10.7   \n",
       "8800             -1.5             -6.3        –•–µ—Ä—Å–æ–Ω—Å—å–∫–∞         -2.7   \n",
       "8801             -1.5             -6.3        –•–µ—Ä—Å–æ–Ω—Å—å–∫–∞         -2.7   \n",
       "8802              2.8             -4.7        –•–µ—Ä—Å–æ–Ω—Å—å–∫–∞          2.6   \n",
       "\n",
       "      wind_direction  wind_speed weather_description          date_hour_x  \\\n",
       "0                343        31.2            Overcast  2022-12-02 12:00:00   \n",
       "1                  3        28.5            Overcast  2022-12-02 11:00:00   \n",
       "2                357        29.9       Partly cloudy  2022-12-02 11:00:00   \n",
       "3                  7        25.4            Overcast  2022-12-02 11:00:00   \n",
       "4                357        29.9       Partly cloudy  2022-12-02 11:00:00   \n",
       "...              ...         ...                 ...                  ...   \n",
       "8798             248        45.4        Mainly clear  2023-04-01 09:00:00   \n",
       "8799             245        27.7        Mainly clear  2023-03-30 16:00:00   \n",
       "8800              65        36.1            Overcast  2023-03-10 08:00:00   \n",
       "8801              65        36.1            Overcast  2023-03-10 08:00:00   \n",
       "8802              83        22.1      Drizzle: Light  2023-03-09 11:00:00   \n",
       "\n",
       "                                             tg_message  \n",
       "0     üí• –•–æ—Ç—ñ–Ω—å (–°—É–º—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞—Ä—Ç–∏–ª–µ—Ä—ñ–π—Å—å–∫–æ...  \n",
       "1     üí• –ú–∞—Ä–≥–∞–Ω–µ—Ü—å (–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞...  \n",
       "2     üí• –ú–∞—Ä–≥–∞–Ω–µ—Ü—å (–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞...  \n",
       "3     üí• –ú–∞—Ä–≥–∞–Ω–µ—Ü—å (–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞...  \n",
       "4     üí• –ú–∞—Ä–≥–∞–Ω–µ—Ü—å (–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞...  \n",
       "...                                                 ...  \n",
       "8798  –•–µ—Ä—Å–æ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å. –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è —â–æ–¥–æ –≤–æ—Ä–æ–∂–∏—Ö –æ–±...  \n",
       "8799  ‚Äã‚Äã‚ö°Ô∏è–û—Ç—Ä–∏–º–∞–≤ –æ—Å–∫–æ–ª–∫–æ–≤–µ –ø–æ—Ä–∞–Ω–µ–Ω–Ω—è –ø—ñ–¥ —á–∞—Å –±–æ–º–±–∞—Ä...  \n",
       "8800  –•–µ—Ä—Å–æ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å. –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è —â–æ–¥–æ –≤–æ—Ä–æ–∂–∏—Ö –æ–±...  \n",
       "8801  –•–µ—Ä—Å–æ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å. –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è —â–æ–¥–æ –≤–æ—Ä–æ–∂–∏—Ö –æ–±...  \n",
       "8802  –ù–∞ –≤—ñ–¥–µ–æ - –ø–ª–æ—â–∞ –ö–æ—Ä–∞–±–µ–ª—å–Ω–∞ —É –•–µ—Ä—Å–æ–Ω—ñ. \\n\\n–ù–∞ ...  \n",
       "\n",
       "[8803 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"message-weather.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean columns\n",
    "\n",
    "First of all, we rename columns `tg_message` to `message_text`, `latitude_decimal` to `latitude`, `longitude_decimal` to `longitude` and `region_x` to `region` for names to be understandable and easy-to-use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename(\n",
    "    columns={\n",
    "        \"tg_message\": \"message_text\",\n",
    "        \"latitude_decimal\": \"latitude\",\n",
    "        \"longitude_decimal\": \"longitude\",\n",
    "        \"region_x\": \"region\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a problem with parsing `date_weather` and `date_hour_x`, since those are strings, but have to be dates, so we convert them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.date_weather = pd.to_datetime(dataset.date_weather, format=\"%Y-%m-%d %H:%M\")\n",
    "dataset.date_hour_x = pd.to_datetime(dataset.date_hour_x, format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataset looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>date_weather</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>max_temperature</th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>region</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>date_hour_x</th>\n",
       "      <th>message_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–°—É–º–∏</td>\n",
       "      <td>2022-12-02 12:32:00</td>\n",
       "      <td>50.911944</td>\n",
       "      <td>34.803333</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>–°—É–º—Å—å–∫–∞</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>343</td>\n",
       "      <td>31.2</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>2022-12-02 12:00:00</td>\n",
       "      <td>üí• –•–æ—Ç—ñ–Ω—å (–°—É–º—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞—Ä—Ç–∏–ª–µ—Ä—ñ–π—Å—å–∫–æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–ú–∞—Ä–≥–∞–Ω–µ—Ü—å</td>\n",
       "      <td>2022-12-02 11:33:00</td>\n",
       "      <td>47.644722</td>\n",
       "      <td>34.604167</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3</td>\n",
       "      <td>28.5</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>2022-12-02 11:00:00</td>\n",
       "      <td>üí• –ú–∞—Ä–≥–∞–Ω–µ—Ü—å (–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–î–Ω—ñ–ø—Ä–æ</td>\n",
       "      <td>2022-12-02 11:33:00</td>\n",
       "      <td>48.466111</td>\n",
       "      <td>35.025278</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞</td>\n",
       "      <td>1.7</td>\n",
       "      <td>357</td>\n",
       "      <td>29.9</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>2022-12-02 11:00:00</td>\n",
       "      <td>üí• –ú–∞—Ä–≥–∞–Ω–µ—Ü—å (–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–ù—ñ–∫–æ–ø–æ–ª—å</td>\n",
       "      <td>2022-12-02 11:33:00</td>\n",
       "      <td>47.577222</td>\n",
       "      <td>34.357500</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7</td>\n",
       "      <td>25.4</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>2022-12-02 11:00:00</td>\n",
       "      <td>üí• –ú–∞—Ä–≥–∞–Ω–µ—Ü—å (–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–î–Ω—ñ–ø—Ä–æ</td>\n",
       "      <td>2022-12-02 11:33:00</td>\n",
       "      <td>48.466111</td>\n",
       "      <td>35.025278</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞</td>\n",
       "      <td>1.7</td>\n",
       "      <td>357</td>\n",
       "      <td>29.9</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>2022-12-02 11:00:00</td>\n",
       "      <td>üí• –ú–∞—Ä–≥–∞–Ω–µ—Ü—å (–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8798</th>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω</td>\n",
       "      <td>2023-04-01 09:06:00</td>\n",
       "      <td>46.640000</td>\n",
       "      <td>32.614444</td>\n",
       "      <td>18.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞</td>\n",
       "      <td>16.9</td>\n",
       "      <td>248</td>\n",
       "      <td>45.4</td>\n",
       "      <td>Mainly clear</td>\n",
       "      <td>2023-04-01 09:00:00</td>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å. –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è —â–æ–¥–æ –≤–æ—Ä–æ–∂–∏—Ö –æ–±...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8799</th>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω</td>\n",
       "      <td>2023-03-30 16:20:00</td>\n",
       "      <td>46.640000</td>\n",
       "      <td>32.614444</td>\n",
       "      <td>16.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞</td>\n",
       "      <td>10.7</td>\n",
       "      <td>245</td>\n",
       "      <td>27.7</td>\n",
       "      <td>Mainly clear</td>\n",
       "      <td>2023-03-30 16:00:00</td>\n",
       "      <td>‚Äã‚Äã‚ö°Ô∏è–û—Ç—Ä–∏–º–∞–≤ –æ—Å–∫–æ–ª–∫–æ–≤–µ –ø–æ—Ä–∞–Ω–µ–Ω–Ω—è –ø—ñ–¥ —á–∞—Å –±–æ–º–±–∞—Ä...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8800</th>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω</td>\n",
       "      <td>2023-03-10 08:43:00</td>\n",
       "      <td>46.640000</td>\n",
       "      <td>32.614444</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>65</td>\n",
       "      <td>36.1</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>2023-03-10 08:00:00</td>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å. –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è —â–æ–¥–æ –≤–æ—Ä–æ–∂–∏—Ö –æ–±...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8801</th>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω</td>\n",
       "      <td>2023-03-10 08:43:00</td>\n",
       "      <td>46.640000</td>\n",
       "      <td>32.614444</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>65</td>\n",
       "      <td>36.1</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>2023-03-10 08:00:00</td>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å. –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è —â–æ–¥–æ –≤–æ—Ä–æ–∂–∏—Ö –æ–±...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8802</th>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω</td>\n",
       "      <td>2023-03-09 11:25:00</td>\n",
       "      <td>46.640000</td>\n",
       "      <td>32.614444</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞</td>\n",
       "      <td>2.6</td>\n",
       "      <td>83</td>\n",
       "      <td>22.1</td>\n",
       "      <td>Drizzle: Light</td>\n",
       "      <td>2023-03-09 11:00:00</td>\n",
       "      <td>–ù–∞ –≤—ñ–¥–µ–æ - –ø–ª–æ—â–∞ –ö–æ—Ä–∞–±–µ–ª—å–Ω–∞ —É –•–µ—Ä—Å–æ–Ω—ñ. \\n\\n–ù–∞ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8803 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           city        date_weather   latitude  longitude  max_temperature  \\\n",
       "0          –°—É–º–∏ 2022-12-02 12:32:00  50.911944  34.803333             -0.2   \n",
       "1     –ú–∞—Ä–≥–∞–Ω–µ—Ü—å 2022-12-02 11:33:00  47.644722  34.604167              2.7   \n",
       "2        –î–Ω—ñ–ø—Ä–æ 2022-12-02 11:33:00  48.466111  35.025278              1.7   \n",
       "3      –ù—ñ–∫–æ–ø–æ–ª—å 2022-12-02 11:33:00  47.577222  34.357500              2.4   \n",
       "4        –î–Ω—ñ–ø—Ä–æ 2022-12-02 11:33:00  48.466111  35.025278              1.7   \n",
       "...         ...                 ...        ...        ...              ...   \n",
       "8798     –•–µ—Ä—Å–æ–Ω 2023-04-01 09:06:00  46.640000  32.614444             18.1   \n",
       "8799     –•–µ—Ä—Å–æ–Ω 2023-03-30 16:20:00  46.640000  32.614444             16.2   \n",
       "8800     –•–µ—Ä—Å–æ–Ω 2023-03-10 08:43:00  46.640000  32.614444             -1.5   \n",
       "8801     –•–µ—Ä—Å–æ–Ω 2023-03-10 08:43:00  46.640000  32.614444             -1.5   \n",
       "8802     –•–µ—Ä—Å–æ–Ω 2023-03-09 11:25:00  46.640000  32.614444              2.8   \n",
       "\n",
       "      min_temperature            region  temperature  wind_direction  \\\n",
       "0                -3.3           –°—É–º—Å—å–∫–∞         -0.2             343   \n",
       "1                -0.1  –î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞          2.7               3   \n",
       "2                -1.6  –î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞          1.7             357   \n",
       "3                 0.1  –î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞          2.4               7   \n",
       "4                -1.6  –î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞          1.7             357   \n",
       "...               ...               ...          ...             ...   \n",
       "8798             10.2        –•–µ—Ä—Å–æ–Ω—Å—å–∫–∞         16.9             248   \n",
       "8799              3.1        –•–µ—Ä—Å–æ–Ω—Å—å–∫–∞         10.7             245   \n",
       "8800             -6.3        –•–µ—Ä—Å–æ–Ω—Å—å–∫–∞         -2.7              65   \n",
       "8801             -6.3        –•–µ—Ä—Å–æ–Ω—Å—å–∫–∞         -2.7              65   \n",
       "8802             -4.7        –•–µ—Ä—Å–æ–Ω—Å—å–∫–∞          2.6              83   \n",
       "\n",
       "      wind_speed weather_description         date_hour_x  \\\n",
       "0           31.2            Overcast 2022-12-02 12:00:00   \n",
       "1           28.5            Overcast 2022-12-02 11:00:00   \n",
       "2           29.9       Partly cloudy 2022-12-02 11:00:00   \n",
       "3           25.4            Overcast 2022-12-02 11:00:00   \n",
       "4           29.9       Partly cloudy 2022-12-02 11:00:00   \n",
       "...          ...                 ...                 ...   \n",
       "8798        45.4        Mainly clear 2023-04-01 09:00:00   \n",
       "8799        27.7        Mainly clear 2023-03-30 16:00:00   \n",
       "8800        36.1            Overcast 2023-03-10 08:00:00   \n",
       "8801        36.1            Overcast 2023-03-10 08:00:00   \n",
       "8802        22.1      Drizzle: Light 2023-03-09 11:00:00   \n",
       "\n",
       "                                           message_text  \n",
       "0     üí• –•–æ—Ç—ñ–Ω—å (–°—É–º—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞—Ä—Ç–∏–ª–µ—Ä—ñ–π—Å—å–∫–æ...  \n",
       "1     üí• –ú–∞—Ä–≥–∞–Ω–µ—Ü—å (–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞...  \n",
       "2     üí• –ú–∞—Ä–≥–∞–Ω–µ—Ü—å (–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞...  \n",
       "3     üí• –ú–∞—Ä–≥–∞–Ω–µ—Ü—å (–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞...  \n",
       "4     üí• –ú–∞—Ä–≥–∞–Ω–µ—Ü—å (–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞ –æ–±–ª.)\\n–ó–∞–≥—Ä–æ–∑–∞ –∞...  \n",
       "...                                                 ...  \n",
       "8798  –•–µ—Ä—Å–æ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å. –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è —â–æ–¥–æ –≤–æ—Ä–æ–∂–∏—Ö –æ–±...  \n",
       "8799  ‚Äã‚Äã‚ö°Ô∏è–û—Ç—Ä–∏–º–∞–≤ –æ—Å–∫–æ–ª–∫–æ–≤–µ –ø–æ—Ä–∞–Ω–µ–Ω–Ω—è –ø—ñ–¥ —á–∞—Å –±–æ–º–±–∞—Ä...  \n",
       "8800  –•–µ—Ä—Å–æ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å. –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è —â–æ–¥–æ –≤–æ—Ä–æ–∂–∏—Ö –æ–±...  \n",
       "8801  –•–µ—Ä—Å–æ–Ω—Å—å–∫–∞ –æ–±–ª–∞—Å—Ç—å. –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è —â–æ–¥–æ –≤–æ—Ä–æ–∂–∏—Ö –æ–±...  \n",
       "8802  –ù–∞ –≤—ñ–¥–µ–æ - –ø–ª–æ—â–∞ –ö–æ—Ä–∞–±–µ–ª—å–Ω–∞ —É –•–µ—Ä—Å–æ–Ω—ñ. \\n\\n–ù–∞ ...  \n",
       "\n",
       "[8803 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examination\n",
    "\n",
    "For further cleanup, it would be great to examine data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates\n",
    "\n",
    "We can see that the `date_weather` is precise date (minute precision), but in comparison `date_hour_x` is not (hour precision). It would be great to examine their relation in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                         8803\n",
       "mean     0 days 00:30:25.239123026\n",
       "std      0 days 00:17:11.615431718\n",
       "min                0 days 00:00:00\n",
       "25%                0 days 00:15:00\n",
       "50%                0 days 00:32:00\n",
       "75%                0 days 00:45:00\n",
       "max                0 days 00:59:00\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = dataset[\"date_weather\"] - dataset[\"date_hour_x\"]\n",
    "dataset.groupby(diff).count().plot.line(y=\"message_text\", legend=False)\n",
    "diff.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the `date_weather` stands between `date_hour_x` and `date_hour_x + 1h` (if we look at the maximum value of the difference) we can suppose, that `date_hour_x` actually equals `date_weather` without minutes component. So let's check this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataset[\"date_weather\"].dt.floor(\"h\") == dataset[\"date_hour_x\"]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is only 1 unique element (True), that means, that this equality is true for all records in the dataset.\n",
    "\n",
    "Because of this, we can say, that there is an error in the data: weather information is usually measured every hour in 0 minutes, but messages are usually sent in different time, so probably `date_hour_x` must be a time when weather was measured and `date_weather` a time when message was sent. This would explain why `date_hour_x` equals `date_weather` without minutes component: when data was collected, recent weather information was used.\n",
    "\n",
    "To not get confused later, we rename `date_hour_x` to `weather_time` and `date_weather` to `message_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename(\n",
    "    columns={\n",
    "        \"date_hour_x\": \"weather_time\",\n",
    "        \"date_weather\": \"message_time\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In final, we have normalized columns names and got this kind of table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates\n",
    "It would be great to check whether there are duplicates in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in fact, there are a lot of them, so we clean it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_size = len(dataset.index)\n",
    "dataset.drop_duplicates(inplace=True)\n",
    "new_size = len(dataset.index)\n",
    "\n",
    "print(f\"{old_size} -> {new_size}, {(1 - new_size/old_size) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that the dataset size was reduced from 8803 records to 4345 (by 50.64%), meaning that the half of the data were duplicates of the same records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regions\n",
    "It would be great to look how many mentions are there for different regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_per_region = dataset.groupby(\"region\").count()[\"message_text\"]\n",
    "messages_per_region.plot.bar(xlabel=\"–û–±–ª–∞—Å—Ç—å\", ylabel=\"–ö-—Å—Ç—å –∑–≥–∞–¥—É–≤–∞–Ω—å\", legend=False)\n",
    "messages_per_region[\"–ö–∏—ó–≤\"] = messages_per_region[\"–ö–∏—ó–≤—Å—å–∫–∞\"]\n",
    "messages_map = map_.join(messages_per_region, on=\"region\")\n",
    "\n",
    "messages_map.plot(\"message_text\", cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see, that almost all the data is from the eastern and southern regions of Ukraine. In future we will focus only on those regions, so we filter them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eastern_regions = [\n",
    "    \"–°—É–º—Å—å–∫–∞\",\n",
    "    \"–•–∞—Ä–∫—ñ–≤—Å—å–∫–∞\",\n",
    "    \"–î–Ω—ñ–ø—Ä–æ–ø–µ—Ç—Ä–æ–≤—Å—å–∫–∞\",\n",
    "    \"–î–æ–Ω–µ—Ü—å–∫–∞\",\n",
    "    \"–õ—É–≥–∞–Ω—Å—å–∫–∞\",\n",
    "    \"–ó–∞–ø–æ—Ä—ñ–∑—å–∫–∞\",\n",
    "    \"–•–µ—Ä—Å–æ–Ω—Å—å–∫–∞\",\n",
    "    \"–ú–∏–∫–æ–ª–∞—ó–≤—Å—å–∫–∞\",\n",
    "]\n",
    "dataset = dataset[dataset.region.isin(eastern_regions)]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are left with 3865 records from eastern regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also there might be other kinds of duplicates. Since the main column of the dataset is telegram message and time when it was sent, we examine how many unique messages are there.\n",
    "\n",
    "Note: we suppose that probability of two identical text messages being sent at the same time and being in this dataset is pretty low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataset.groupby([\"message_text\", \"message_time\"]).size() > 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means, that from 3865 messages there are only around 1618 unique. But since those are not strong duplicates, we can lookup for the difference between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the group of the maximum size\n",
    "group = max(\n",
    "    dataset.groupby([\"message_text\", \"message_time\"]).groups.values(),\n",
    "    key=lambda item: len(item),\n",
    ")\n",
    "dataset.loc[group[:7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the message was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.loc[group[0], \"message_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that the difference is in the city names (and hence the weather). All of the cities in the group were mentioned in the message, so it probably means that those duplicates just mean different towns. We can check this hypothesis by checking whether there are duplicates of values in the form of `(message_time, message_text, city)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.duplicated([\"message_time\", \"message_text\", \"city\"]).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, there are no duplicates of that form, so the dataset actually looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_index([\"message_time\", \"message_text\", \"city\"]).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However we won't update the indices of the dataset, since it is easier to work with denormalized data in pandas, but it would be great to have another copy of the dataset, that contains only those 1618 unique messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_messages = dataset[[\"message_time\", \"message_text\"]].drop_duplicates()\n",
    "dataset_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, we finished with data cleaning, but also we would like to show the plot of the messages reeived per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_messages.groupby(dataset_messages.message_time.dt.round(\"7d\").dt.date).count().plot.bar(\n",
    "    y=\"message_text\", legend=False, xlabel=\"–î–∞—Ç–∞\", ylabel=\"–ö-—Å—Ç—å –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linguistics analysis\n",
    "\n",
    "In this part we will analyse texts of the messages given in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word usage frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We analyze how frequently words are used by nltk library and ukrainian dictionary. This creates new column `words`, which contins Counter, where key is word and value is number of times it was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_lemmatize(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    lemmas = Counter()\n",
    "    for token in tokens:\n",
    "        if not token.isalpha():\n",
    "            continue\n",
    "\n",
    "        lemma = morph.parse(token)[0].normal_form\n",
    "        lemmas[lemma] += 1\n",
    "\n",
    "    return lemmas\n",
    "\n",
    "dataset_messages[\"words\"] = dataset_messages.message_text.apply(tokenize_and_lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we join dataset_messages back to dataset to use words in future with region information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.join(dataset_messages.set_index([\"message_time\", \"message_text\"]), on=[\"message_time\", \"message_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create plot of often used words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.Series(dataset_messages.words.sum())\n",
    "words = words.sort_values()\n",
    "words.iloc[-25:].plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that there are lots of words connected to the war in theese messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create a wordcloud to see the general mood the messages reflect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = \" \".join(dataset_messages['message_text'])\n",
    "\n",
    "picture = wordcloud.WordCloud(width=1920, height=1080, background_color=\"white\").generate(text_data)\n",
    "\n",
    "plt.imshow(picture)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threats counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a set of tokens, that mean some type of threat, and then count how many messages are about threats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threats_lemmas = {\"–æ–±—Å—Ç—Ä—ñ–ª—é–≤–∞–Ω–∏–π\", \"–∞—Ç–∞–∫–æ–≤–∞–Ω–∏–π\", \"–æ–±—Å—Ç—Ä—ñ–ª–ª—é—á–∏\", \"–∞—Ä—Ç–æ–±—Å—Ç—Ä—ñ–ª\", \"–∞—Ç–∞–∫—É–≤–∞—Ç–∏\", \"–æ–±—Å—Ç—Ä—ñ–ª—é–≤–∞—Ç–∏\", \"–∞—Ç–∞–∫–∞\", \"–≤–∏–±—É—Ö\", \"–æ–±—Å—Ç—Ä—ñ–ª—è—Ç–∏\", \"–∑–∞–≥—Ä–æ–∑–∞\", \"–æ–±—Å—Ç—Ä—ñ–ª\"}\n",
    "dataset_messages.words.apply(lambda lemmas: bool(set(lemmas.keys()) & threats_lemmas)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that only 104 messages don't contain those lemmas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Injured people and casualties counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to count injured people and casualties in the messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_regions = dataset[[\"message_time\", \"message_text\", \"region\"]].drop_duplicates()\n",
    "\n",
    "def extract_injured_count(text):\n",
    "    match = re.search(r\"\\b(\\d+)\\s*(?:–ø–æ—Ä–∞–Ω–µ–Ω—ñ|–ø–æ—Ä–∞–Ω–µ–Ω–∏—Ö)\\b\", str(text), re.IGNORECASE)\n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "dataset_regions = dataset_regions.assign(injured_count = dataset_regions.message_text.apply(extract_injured_count))\n",
    "injured_by_region = dataset_regions.groupby(\"region\")[\"injured_count\"].sum()\n",
    "total_injured = injured_by_region.sum()\n",
    "injured_by_region.sort_values().plot.bar()\n",
    "total_injured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the most injured people are in Luhansk and Dnipropetrovsk oblast's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_regions = dataset[[\"message_time\", \"message_text\", \"region\"]].drop_duplicates()\n",
    "\n",
    "def extract_casualties_count(text):\n",
    "    match = re.search(r\"\\b(\\d+)\\s*(?:–ª—é–¥–µ–π\\s*)?(?:–∑–∞–≥–∏–Ω—É–ª–∏|–∑–∞–≥–∏–Ω—É–ª–æ)|(?:–∑–∞–≥–∏–Ω—É–ª–∏|–∑–∞–≥–∏–Ω—É–ª–æ)\\s*(\\d+)\\b\", str(text), re.IGNORECASE)\n",
    "    if match:\n",
    "        return int(match.group(1) or match.group(2))\n",
    "    return 0\n",
    "\n",
    "dataset_regions = dataset_regions.assign(casualties_count = dataset_regions.message_text.apply(extract_casualties_count))\n",
    "casualties_by_region = dataset_regions.groupby(\"region\")[\"casualties_count\"].sum()\n",
    "total_casualties = casualties_by_region.sum()\n",
    "casualties_by_region.sort_values().plot.bar()\n",
    "total_casualties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the most casualties are in Zaporizha, Donetsk and Kherson oblast's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dataset for unique weather records for each region at each time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dataset = dataset.drop_duplicates(['weather_time', 'region'])\n",
    "weather_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we actually have only 1313 records of weather. Let's try to look at wind rose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_data = weather_dataset['wind_direction'].round(-1).value_counts().sort_index()\n",
    "ax = plt.axes(projection=\"polar\")\n",
    "ax.set_theta_zero_location(\"N\")\n",
    "ax.set_theta_direction(-1)\n",
    "plt.plot(np.deg2rad(wind_data.index),wind_data.values,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the winds are directed to south-west. Let's see which wind speed tends to be there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "north_east_wind_speed = weather_dataset[(180<weather_dataset['wind_direction']) & (weather_dataset['wind_direction'] <= 270)].groupby(\"weather_time\").wind_speed.mean()\n",
    "north_east_wind_speed.plot.line()\n",
    "north_east_wind_speed.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a gap of weather in December and March. And the mean speed of the weather is 25 (while speed itself is between 0 and 50 km/h). We suppose that wind is measured in km/h because 50 m/s is very anomalic wind (hurricane), there is a low possibility of that. \n",
    "\n",
    "Also we want to see temperature plot for the Eastern Ukraine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dataset.assign(date=weather_dataset['message_time'].dt.date).groupby('date')['temperature'].mean().plot(kind='line', marker='o', xlabel=\"–î–∞—Ç–∞\", ylabel='–°–µ—Ä–µ–¥–Ω—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ (¬∞C)')\n",
    "\n",
    "temperature_per_region = dataset.groupby(\"region\")[\"temperature\"].mean()\n",
    "temperature_map = map_.join(temperature_per_region, on=\"region\")\n",
    "temperature_map.plot(\"temperature\", cmap=\"Blues\", legend=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
